{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Girl, I'm fucking cumming! you're the 515-th girl I've fucked.\n",
      "          You'll recieve 114 mL of my cum.\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "\n",
    "class fucker:\n",
    "    def __init__(self, cum_amount, fuck_cunt_cnt):\n",
    "        self.cum_amount = cum_amount\n",
    "        self.fuck_cunt_cnt = fuck_cunt_cnt\n",
    "\n",
    "    def fuck(self, girl:str):\n",
    "        print(f\"Yes!!!{self.cum_amount}\")\n",
    "        self.fuck_cunt_cnt +=1\n",
    "\n",
    "Qiyu = fucker(114, 514)\n",
    "\n",
    "def new_fuck(self, girl:str):\n",
    "    self.fuck_cunt_cnt +=1\n",
    "    print(f\"{girl}, I'm fucking cumming! you're the {self.fuck_cunt_cnt}-th girl I've fucked.\\n\\\n",
    "          You'll recieve {self.cum_amount} mL of my cum.\")\n",
    "\n",
    "Qiyu.fuck = types.MethodType(new_fuck, Qiyu)\n",
    "\n",
    "Qiyu.fuck(\"Girl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm fucking horny!\n",
      "Yes!!!114\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "class new_fucker(fucker):\n",
    "    def __init__(self, cum_amount, fuck_cunt_cnt):\n",
    "        super().__init__(cum_amount, fuck_cunt_cnt)\n",
    "        self.old_fuck = copy.copy(self.fuck)\n",
    "        def fuck(girl:str):\n",
    "            print(\"I'm fucking horny!\")\n",
    "            self.old_fuck(girl)\n",
    "        self.fuck = fuck\n",
    "\n",
    "me = new_fucker(114, 514)\n",
    "\n",
    "me.fuck(\"Girl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(me, 'old_fuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/yichen/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from neuralop.models import FNO, AttnFNO2D\n",
    "\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import OutputEncoderCallback\n",
    "from neuralop.utils import count_params\n",
    "from neuralop import LpLoss, H1Loss\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "from neuralop.datasets.autoregressive_dataset import load_autoregressive_traintestsplit\n",
    "data_path = \"./data/NavierStokes_V1e-5_N1200_T20.mat\"\n",
    "\n",
    "n_train = 1000\n",
    "n_test = 200\n",
    "batch_size = 32\n",
    "test_batch_size = 64\n",
    "train_subsample_rate = 1\n",
    "test_subsample_rate = 1\n",
    "time_step = 1\n",
    "train_loader, test_loader = load_autoregressive_traintestsplit(\n",
    "    data_path,\n",
    "    n_train, n_test,\n",
    "    batch_size, test_batch_size, \n",
    "    train_subsample_rate, test_subsample_rate,\n",
    "    time_step,\n",
    "    predict_feature='u',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we would first establish a similar dataset adapter.\n",
    "\n",
    "input: train loader\n",
    "\n",
    "output: a new test loader\n",
    "\n",
    "transform rule:\n",
    "u1 = u / k; \n",
    "visc1 = visc / k; \n",
    "f1 = f / k**2; \n",
    "\n",
    "index rule: \n",
    "if the k list has length $n_k$, then for idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TFNO_prodlayer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our TFNO_prodlayer model has 539809 parameters.\n"
     ]
    }
   ],
   "source": [
    "# We create a tensorized FNO model\n",
    "\n",
    "input_prods = None\n",
    "n_modes=21\n",
    "\n",
    "# model = FNO(in_channels=3, n_modes=(n_modes, n_modes), hidden_channels=32, \n",
    "#              projection_channels=64, factorization=None, channel_mixing='prod-layer', stabilizer='tanh', rank=0.)\n",
    "\n",
    "model = AttnFNO2D(in_channels=3, n_modes=(n_modes, n_modes), hidden_channels=32, \n",
    "             projection_channels=64, factorization=None, channel_mixing='', stabilizer='tanh', rank=0.,\n",
    "             norm='instance_norm')\n",
    "\n",
    "# method_name = type(model).__name__.split('.')[-1]\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "n_params = count_params(model)\n",
    "print(f'\\nOur '+model_name+f' model has {n_params} parameters.')\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MODEL ###\n",
      " AttnFNO2D(\n",
      "  (fno_blocks): FNOBlocks1(\n",
      "    (convs): SpectralConvAttn2d(\n",
      "      (attn_blocks_x): ModuleList(\n",
      "        (0-3): 4 x SpectralAttetionBlock2D(\n",
      "          (Wq): ComplexDenseTensor(shape=torch.Size([2, 32, 32]), rank=None)\n",
      "          (Wk): ComplexDenseTensor(shape=torch.Size([2, 10, 32, 32]), rank=None)\n",
      "          (Wv): ComplexDenseTensor(shape=torch.Size([2, 10, 32, 16]), rank=None)\n",
      "        )\n",
      "      )\n",
      "      (attn_blocks_y): ModuleList(\n",
      "        (0-3): 4 x SpectralAttetionBlock2D(\n",
      "          (Wq): ComplexDenseTensor(shape=torch.Size([2, 32, 32]), rank=None)\n",
      "          (Wk): ComplexDenseTensor(shape=torch.Size([2, 10, 32, 32]), rank=None)\n",
      "          (Wv): ComplexDenseTensor(shape=torch.Size([2, 10, 32, 16]), rank=None)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (norm): ModuleList(\n",
      "      (0-3): 4 x InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (lifting): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (projection): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.StepLR object at 0x770e885f9930>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x770e885fa410>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x770e885fa410>, 'l2': <neuralop.training.losses.LpLoss object at 0x770e885f8f10>}\n"
     ]
    }
   ],
   "source": [
    "#Create the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                lr=1e-3, \n",
    "                                weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "# Creating the losses\n",
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "\n",
    "print('\\n### MODEL ###\\n', model)\n",
    "print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "print('\\n### LOSSES ###')\n",
    "print(f'\\n * Train: {train_loss}')\n",
    "print(f'\\n * Test: {eval_losses}')\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "localtime = time.localtime(time.time())\n",
    "time_now = f\"{localtime.tm_mon}-{localtime.tm_mday}-{localtime.tm_hour}-{localtime.tm_min}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 00:38:26.840770: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-30 00:38:26.862235: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-30 00:38:26.862260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-30 00:38:26.862923: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-30 00:38:26.866688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 00:38:27.359372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using standard method to load data to device.\n",
      "using standard method to compute loss.\n",
      "self.override_load_to_device=False\n",
      "self.overrides_loss=False\n"
     ]
    }
   ],
   "source": [
    "from neuralop.training import MultipleInputCallback, SimpleTensorBoardLoggerCallback\n",
    "trainer = Trainer(model=model, n_epochs=500,\n",
    "                  device=device,\n",
    "                  callbacks=[MultipleInputCallback(append_positional_encoding=True), SimpleTensorBoardLoggerCallback(log_dir='runs/TorisLi_exp_'+model_name+time_now,)],             \n",
    "                  wandb_log=False,\n",
    "                  log_test_interval=4,\n",
    "                  use_distributed=False,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 19000 samples\n",
      "Testing on [3800] samples         on resolutions [64].\n",
      "Raw outputs of size out.shape=torch.Size([32, 1, 64, 64])\n",
      "[0] time=9.67, avg_loss=0.0480, train_err=0.0013, 64_h1=1.0007, 64_l2=1.0000\n",
      "[4] time=9.39, avg_loss=0.0305, train_err=0.0008, 64_h1=0.6445, 64_l2=0.3769\n",
      "[8] time=9.28, avg_loss=0.0325, train_err=0.0009, 64_h1=0.6283, 64_l2=0.3328\n",
      "[12] time=9.49, avg_loss=nan, train_err=nan, 64_h1=nan, 64_l2=nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtraining_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43meval_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_losses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/cfd/myNeuralOperator/neuralop/training/trainer.py:216\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, test_loaders, optimizer, scheduler, regularizer, training_loss, eval_losses)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m regularizer:\n\u001b[1;32m    214\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m regularizer\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m--> 216\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    220\u001b[0m train_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader=train_loader,\n",
    "              test_loaders={64: test_loader},\n",
    "              optimizer=optimizer, \n",
    "              scheduler=scheduler, \n",
    "              regularizer=False, \n",
    "              training_loss=train_loss, \n",
    "              eval_losses=eval_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./test_param_search/b_64/mode_21/prod_2/layer_4/hid_32/lift_256/proj_64/fact-/rank_0.42/mix-/pos-enc-True/lr_0.001/wd_0/sche-step_100/gamma_0.5/loss-h1/TorusLi_FNO_1-17-19-20.pth'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import torch\n",
    "\n",
    "temp_dir = tempfile.gettempdir()\n",
    "temp_file_path = os.path.join(temp_dir, 'temp_model.pth')\n",
    "torch.save(trainer.model.state_dict(), temp_file_path)\n",
    "\n",
    "target_path = './test_param_search/b_64/mode_21/prod_2/layer_4/hid_32/lift_256/proj_64/fact-/rank_0.42/mix-/pos-enc-True/lr_0.001/wd_0/sche-step_100/gamma_0.5/loss-h1/TorusLi_FNO_1-17-19-20.pth'\n",
    "\n",
    "target_dir = os.path.dirname(target_path)\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "shutil.move(temp_file_path, target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = './test_param_search/b_64/mode_21/prod_2/TorusLi_FNO_1-17-19-20.pth'\n",
    "\n",
    "# Create directories if they do not exist\n",
    "dir_path = os.path.dirname(path)\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# Save the model\n",
    "torch.save(trainer.model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), \"./ckpt/TorisLi/\"+model_name+\"_ep500.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_44388/849268122.py\", line 11, in <module>\n",
      "    out = model(x.unsqueeze(0))\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/repo/cfd/myNeuralOperator/neuralop/models/new_fno.py\", line 252, in forward\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/repo/cfd/myNeuralOperator/neuralop/layers/mlp.py\", line 62, in forward\n",
      "    x = fc(x)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Given groups=1, weight of size [256, 3, 1, 1], expected input[1, 1, 64, 64] to have 3 channels, but got 1 channels instead\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = test_loader.dataset\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "for index in range(3):\n",
    "    data = test_samples[index]\n",
    "    # Input x\n",
    "    x = data['x']\n",
    "    # Ground-truth\n",
    "    y = data['y']\n",
    "    # Model prediction\n",
    "    out = model(x.unsqueeze(0))\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 1)\n",
    "    ax.imshow(x[0], cmap='gray')\n",
    "    if index == 0: \n",
    "        ax.set_title('Input x')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 2)\n",
    "    ax.imshow(y.squeeze())\n",
    "    if index == 0: \n",
    "        ax.set_title('Ground-truth y')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 3)\n",
    "    ax.imshow(out.squeeze().detach().numpy())\n",
    "    if index == 0: \n",
    "        ax.set_title('Model prediction')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "fig.suptitle('Inputs, ground-truth output and prediction.', y=0.98)\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
