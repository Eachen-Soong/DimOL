{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from neuralop.models import FNO, F_FNO2D\n",
    "\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import OutputEncoderCallback\n",
    "from neuralop.utils import count_params\n",
    "from neuralop import LpLoss, H1Loss\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "from neuralop.datasets.autoregressive_dataset import load_autoregressive_traintestsplit\n",
    "data_path = \"/home/yichen/repo/cfd/myFNO/data/zongyi/NavierStokes_V1e-5_N1200_T20.mat\"\n",
    "\n",
    "n_train = 1000\n",
    "n_test = 200\n",
    "batch_size = 32\n",
    "test_batch_size = 64\n",
    "train_subsample_rate = 1\n",
    "test_subsample_rate = 1\n",
    "time_step = 1\n",
    "train_loader, test_loader = load_autoregressive_traintestsplit(\n",
    "    data_path,\n",
    "    n_train, n_test,\n",
    "    batch_size, test_batch_size, \n",
    "    train_subsample_rate, test_subsample_rate,\n",
    "    time_step,\n",
    "    predict_feature='u',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"FFNO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our FFNO model has 186369 parameters.\n"
     ]
    }
   ],
   "source": [
    "# We create a F-FNO model\n",
    "\n",
    "input_prods = None\n",
    "n_modes=21\n",
    "\n",
    "model = F_FNO2D(in_channels=3, n_modes=(n_modes, n_modes), hidden_channels=32, \n",
    "             projection_channels=64, factorization='tucker', channel_mixing='prod-layer', ffno_channel_mixing='prod', stabilizer='tanh', rank=0.42)\n",
    "\n",
    "# model = FNO(in_channels=3, n_modes=(n_modes, n_modes), hidden_channels=32, \n",
    "#              projection_channels=64, factorization='tucker', channel_mixing='prod-layer', stabilizer='tanh', rank=0.42)\n",
    "\n",
    "# method_name = type(model).__name__.split('.')[-1]\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "n_params = count_params(model)\n",
    "print(f'\\nOur '+model_name+f' model has {n_params} parameters.')\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MODEL ###\n",
      " F_FNO2D(\n",
      "  (fno_blocks): F_FNOBlocks2D(\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (channel_mixer): ModuleList(\n",
      "      (0-3): 4 x ProductLayer(\n",
      "        (linear): MLP(\n",
      "          (fcs): ModuleList(\n",
      "            (0): Conv2d(34, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mixer_skips): ModuleList(\n",
      "      (0-3): 4 x SoftGating()\n",
      "    )\n",
      "    (convs): SpectralConvFFNO2d(\n",
      "      (weight): ModuleList(\n",
      "        (0-7): 8 x ComplexDenseTensor(shape=torch.Size([32, 32, 10]), rank=None)\n",
      "      )\n",
      "      (linear): MLP(\n",
      "        (fcs): ModuleList(\n",
      "          (0): Conv2d(66, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lifting): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (projection): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.StepLR object at 0x7f441826f370>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x7f441826d570>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x7f441826d570>, 'l2': <neuralop.training.losses.LpLoss object at 0x7f441826de10>}\n"
     ]
    }
   ],
   "source": [
    "#Create the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                lr=1e-3, \n",
    "                                weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "# Creating the losses\n",
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "\n",
    "print('\\n### MODEL ###\\n', model)\n",
    "print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "print('\\n### LOSSES ###')\n",
    "print(f'\\n * Train: {train_loss}')\n",
    "print(f'\\n * Test: {eval_losses}')\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "localtime = time.localtime(time.time())\n",
    "time_now = f\"{localtime.tm_mon}-{localtime.tm_mday}-{localtime.tm_hour}-{localtime.tm_min}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 23:19:50.844477: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-16 23:19:50.864949: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-16 23:19:50.864974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-16 23:19:50.865487: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-16 23:19:50.868882: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 23:19:51.248956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using standard method to load data to device.\n",
      "using standard method to compute loss.\n",
      "self.override_load_to_device=False\n",
      "self.overrides_loss=False\n"
     ]
    }
   ],
   "source": [
    "from neuralop.training import MultipleInputCallback, SimpleTensorBoardLoggerCallback\n",
    "trainer = Trainer(model=model, n_epochs=500,\n",
    "                  device=device,\n",
    "                  callbacks=[MultipleInputCallback(append_positional_encoding=True), SimpleTensorBoardLoggerCallback(log_dir='runs/TorisLi_exp_'+model_name+time_now,)],             \n",
    "                  wandb_log=False,\n",
    "                  log_test_interval=4,\n",
    "                  use_distributed=False,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 19000 samples\n",
      "Testing on [3800] samples         on resolutions [64].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw outputs of size out.shape=torch.Size([32, 1, 64, 64])\n",
      "[0] time=10.51, avg_loss=15.9375, train_err=13.4154, 64_h1=0.3264, 64_l2=0.1214\n",
      "[4] time=10.08, avg_loss=8.6298, train_err=7.2641, 64_h1=0.2287, 64_l2=0.0814\n",
      "[8] time=10.38, avg_loss=7.4644, train_err=6.2832, 64_h1=0.1969, 64_l2=0.0639\n",
      "[12] time=10.38, avg_loss=6.9025, train_err=5.8102, 64_h1=0.1877, 64_l2=0.0638\n",
      "[16] time=10.34, avg_loss=6.5256, train_err=5.4929, 64_h1=0.1733, 64_l2=0.0539\n",
      "[20] time=10.57, avg_loss=6.2702, train_err=5.2779, 64_h1=0.1709, 64_l2=0.0600\n",
      "[24] time=10.03, avg_loss=6.0796, train_err=5.1175, 64_h1=0.1636, 64_l2=0.0542\n",
      "[28] time=10.09, avg_loss=5.9039, train_err=4.9696, 64_h1=0.1580, 64_l2=0.0500\n",
      "[32] time=10.09, avg_loss=5.7882, train_err=4.8722, 64_h1=0.1594, 64_l2=0.0535\n",
      "[36] time=10.01, avg_loss=5.6841, train_err=4.7846, 64_h1=0.1530, 64_l2=0.0495\n",
      "[40] time=10.17, avg_loss=5.5751, train_err=4.6928, 64_h1=0.1503, 64_l2=0.0483\n",
      "[44] time=9.93, avg_loss=5.4639, train_err=4.5992, 64_h1=0.1497, 64_l2=0.0502\n",
      "[48] time=10.47, avg_loss=5.3920, train_err=4.5387, 64_h1=0.1470, 64_l2=0.0472\n",
      "[52] time=10.13, avg_loss=5.3241, train_err=4.4815, 64_h1=0.1436, 64_l2=0.0515\n",
      "[56] time=10.29, avg_loss=5.2549, train_err=4.4233, 64_h1=0.1442, 64_l2=0.0449\n",
      "[60] time=10.81, avg_loss=5.1984, train_err=4.3757, 64_h1=0.1546, 64_l2=0.0509\n",
      "[64] time=10.16, avg_loss=5.1340, train_err=4.3216, 64_h1=0.1384, 64_l2=0.0419\n",
      "[68] time=10.10, avg_loss=5.0951, train_err=4.2888, 64_h1=0.1415, 64_l2=0.0529\n",
      "[72] time=10.60, avg_loss=5.0273, train_err=4.2318, 64_h1=0.1376, 64_l2=0.0480\n",
      "[76] time=10.19, avg_loss=5.0036, train_err=4.2118, 64_h1=0.1370, 64_l2=0.0443\n",
      "[80] time=9.97, avg_loss=4.9526, train_err=4.1689, 64_h1=0.1344, 64_l2=0.0421\n",
      "[84] time=9.98, avg_loss=4.9313, train_err=4.1509, 64_h1=0.1345, 64_l2=0.0433\n",
      "[88] time=10.31, avg_loss=4.8975, train_err=4.1225, 64_h1=0.1329, 64_l2=0.0467\n",
      "[92] time=10.18, avg_loss=4.8568, train_err=4.0882, 64_h1=0.1327, 64_l2=0.0410\n",
      "[96] time=9.99, avg_loss=4.8458, train_err=4.0789, 64_h1=0.1295, 64_l2=0.0397\n",
      "[100] time=9.95, avg_loss=4.6402, train_err=3.9059, 64_h1=0.1263, 64_l2=0.0372\n",
      "[104] time=10.29, avg_loss=4.6502, train_err=3.9143, 64_h1=0.1267, 64_l2=0.0375\n",
      "[108] time=10.08, avg_loss=4.6369, train_err=3.9032, 64_h1=0.1261, 64_l2=0.0410\n",
      "[112] time=10.02, avg_loss=4.6121, train_err=3.8822, 64_h1=0.1256, 64_l2=0.0392\n",
      "[116] time=10.18, avg_loss=4.5864, train_err=3.8606, 64_h1=0.1244, 64_l2=0.0371\n",
      "[120] time=10.07, avg_loss=4.5742, train_err=3.8503, 64_h1=0.1260, 64_l2=0.0398\n",
      "[124] time=9.95, avg_loss=4.5711, train_err=3.8477, 64_h1=0.1241, 64_l2=0.0380\n",
      "[128] time=10.20, avg_loss=4.5542, train_err=3.8335, 64_h1=0.1235, 64_l2=0.0373\n",
      "[132] time=10.09, avg_loss=4.5352, train_err=3.8175, 64_h1=0.1239, 64_l2=0.0392\n",
      "[136] time=10.13, avg_loss=4.5269, train_err=3.8105, 64_h1=0.1235, 64_l2=0.0378\n",
      "[140] time=10.18, avg_loss=4.5089, train_err=3.7953, 64_h1=0.1238, 64_l2=0.0412\n",
      "[144] time=9.98, avg_loss=4.4922, train_err=3.7813, 64_h1=0.1233, 64_l2=0.0369\n",
      "[148] time=10.07, avg_loss=4.4896, train_err=3.7791, 64_h1=0.1220, 64_l2=0.0363\n",
      "[152] time=10.04, avg_loss=4.4709, train_err=3.7634, 64_h1=0.1213, 64_l2=0.0356\n",
      "[156] time=9.97, avg_loss=4.4439, train_err=3.7407, 64_h1=0.1216, 64_l2=0.0365\n",
      "[160] time=10.00, avg_loss=4.4471, train_err=3.7433, 64_h1=0.1210, 64_l2=0.0357\n",
      "[164] time=10.18, avg_loss=4.4398, train_err=3.7372, 64_h1=0.1217, 64_l2=0.0376\n",
      "[168] time=10.28, avg_loss=4.4282, train_err=3.7275, 64_h1=0.1210, 64_l2=0.0365\n",
      "[172] time=10.34, avg_loss=4.4288, train_err=3.7280, 64_h1=0.1212, 64_l2=0.0389\n",
      "[176] time=10.42, avg_loss=4.4090, train_err=3.7113, 64_h1=0.1198, 64_l2=0.0356\n",
      "[180] time=10.04, avg_loss=4.3944, train_err=3.6990, 64_h1=0.1203, 64_l2=0.0359\n",
      "[184] time=10.16, avg_loss=4.3794, train_err=3.6863, 64_h1=0.1199, 64_l2=0.0364\n",
      "[188] time=10.39, avg_loss=4.3885, train_err=3.6940, 64_h1=0.1199, 64_l2=0.0379\n",
      "[192] time=10.18, avg_loss=4.3806, train_err=3.6873, 64_h1=0.1196, 64_l2=0.0390\n",
      "[196] time=9.90, avg_loss=4.3676, train_err=3.6764, 64_h1=0.1207, 64_l2=0.0378\n",
      "[200] time=9.97, avg_loss=4.2746, train_err=3.5982, 64_h1=0.1165, 64_l2=0.0335\n",
      "[204] time=10.08, avg_loss=4.2784, train_err=3.6013, 64_h1=0.1169, 64_l2=0.0341\n",
      "[208] time=10.06, avg_loss=4.2706, train_err=3.5947, 64_h1=0.1173, 64_l2=0.0352\n",
      "[212] time=10.03, avg_loss=4.2627, train_err=3.5881, 64_h1=0.1173, 64_l2=0.0352\n",
      "[216] time=10.02, avg_loss=4.2650, train_err=3.5900, 64_h1=0.1165, 64_l2=0.0340\n",
      "[220] time=9.93, avg_loss=4.2565, train_err=3.5830, 64_h1=0.1163, 64_l2=0.0338\n",
      "[224] time=9.98, avg_loss=4.2455, train_err=3.5737, 64_h1=0.1163, 64_l2=0.0338\n",
      "[228] time=10.01, avg_loss=4.2437, train_err=3.5721, 64_h1=0.1160, 64_l2=0.0337\n",
      "[232] time=10.36, avg_loss=4.2361, train_err=3.5657, 64_h1=0.1160, 64_l2=0.0348\n",
      "[236] time=10.40, avg_loss=4.2313, train_err=3.5617, 64_h1=0.1164, 64_l2=0.0344\n",
      "[240] time=10.09, avg_loss=4.2254, train_err=3.5567, 64_h1=0.1157, 64_l2=0.0336\n",
      "[244] time=10.26, avg_loss=4.2259, train_err=3.5572, 64_h1=0.1168, 64_l2=0.0366\n",
      "[248] time=10.15, avg_loss=4.2148, train_err=3.5478, 64_h1=0.1151, 64_l2=0.0336\n",
      "[252] time=10.06, avg_loss=4.2161, train_err=3.5489, 64_h1=0.1158, 64_l2=0.0350\n",
      "[256] time=10.00, avg_loss=4.2096, train_err=3.5435, 64_h1=0.1180, 64_l2=0.0386\n",
      "[260] time=9.97, avg_loss=4.2013, train_err=3.5365, 64_h1=0.1152, 64_l2=0.0353\n",
      "[264] time=10.18, avg_loss=4.2007, train_err=3.5360, 64_h1=0.1152, 64_l2=0.0346\n",
      "[268] time=10.07, avg_loss=4.1905, train_err=3.5273, 64_h1=0.1145, 64_l2=0.0337\n",
      "[272] time=10.20, avg_loss=4.1884, train_err=3.5256, 64_h1=0.1148, 64_l2=0.0336\n",
      "[276] time=10.47, avg_loss=4.1834, train_err=3.5214, 64_h1=0.1148, 64_l2=0.0340\n",
      "[280] time=10.08, avg_loss=4.1812, train_err=3.5195, 64_h1=0.1149, 64_l2=0.0356\n",
      "[284] time=10.00, avg_loss=4.1758, train_err=3.5150, 64_h1=0.1146, 64_l2=0.0333\n",
      "[288] time=10.54, avg_loss=4.1742, train_err=3.5136, 64_h1=0.1143, 64_l2=0.0332\n",
      "[292] time=10.05, avg_loss=4.1672, train_err=3.5077, 64_h1=0.1142, 64_l2=0.0342\n",
      "[296] time=10.33, avg_loss=4.1637, train_err=3.5048, 64_h1=0.1141, 64_l2=0.0331\n",
      "[300] time=10.02, avg_loss=4.1176, train_err=3.4660, 64_h1=0.1132, 64_l2=0.0326\n",
      "[304] time=10.05, avg_loss=4.1206, train_err=3.4685, 64_h1=0.1137, 64_l2=0.0336\n",
      "[308] time=10.51, avg_loss=4.1187, train_err=3.4669, 64_h1=0.1128, 64_l2=0.0329\n",
      "[312] time=10.15, avg_loss=4.1157, train_err=3.4644, 64_h1=0.1129, 64_l2=0.0323\n",
      "[316] time=10.16, avg_loss=4.1120, train_err=3.4613, 64_h1=0.1131, 64_l2=0.0335\n",
      "[320] time=10.08, avg_loss=4.1099, train_err=3.4595, 64_h1=0.1127, 64_l2=0.0327\n",
      "[324] time=9.90, avg_loss=4.1076, train_err=3.4576, 64_h1=0.1127, 64_l2=0.0324\n",
      "[328] time=9.99, avg_loss=4.1044, train_err=3.4549, 64_h1=0.1126, 64_l2=0.0325\n",
      "[332] time=10.34, avg_loss=4.1030, train_err=3.4537, 64_h1=0.1124, 64_l2=0.0330\n",
      "[336] time=10.19, avg_loss=4.1014, train_err=3.4524, 64_h1=0.1124, 64_l2=0.0324\n",
      "[340] time=10.24, avg_loss=4.0990, train_err=3.4503, 64_h1=0.1123, 64_l2=0.0322\n",
      "[344] time=10.11, avg_loss=4.0948, train_err=3.4468, 64_h1=0.1120, 64_l2=0.0319\n",
      "[348] time=10.11, avg_loss=4.0953, train_err=3.4472, 64_h1=0.1120, 64_l2=0.0321\n",
      "[352] time=10.09, avg_loss=4.0900, train_err=3.4428, 64_h1=0.1121, 64_l2=0.0325\n",
      "[356] time=10.08, avg_loss=4.0918, train_err=3.4443, 64_h1=0.1124, 64_l2=0.0325\n",
      "[360] time=10.09, avg_loss=4.0842, train_err=3.4379, 64_h1=0.1122, 64_l2=0.0334\n",
      "[364] time=10.00, avg_loss=4.0841, train_err=3.4378, 64_h1=0.1121, 64_l2=0.0325\n",
      "[368] time=10.15, avg_loss=4.0803, train_err=3.4346, 64_h1=0.1118, 64_l2=0.0320\n",
      "[372] time=10.33, avg_loss=4.0774, train_err=3.4321, 64_h1=0.1119, 64_l2=0.0327\n",
      "[376] time=10.32, avg_loss=4.0770, train_err=3.4318, 64_h1=0.1122, 64_l2=0.0326\n",
      "[380] time=9.95, avg_loss=4.0747, train_err=3.4299, 64_h1=0.1118, 64_l2=0.0322\n",
      "[384] time=9.92, avg_loss=4.0726, train_err=3.4281, 64_h1=0.1118, 64_l2=0.0325\n",
      "[388] time=10.30, avg_loss=4.0709, train_err=3.4266, 64_h1=0.1121, 64_l2=0.0335\n",
      "[392] time=10.18, avg_loss=4.0670, train_err=3.4234, 64_h1=0.1115, 64_l2=0.0317\n",
      "[396] time=10.34, avg_loss=4.0658, train_err=3.4224, 64_h1=0.1113, 64_l2=0.0318\n",
      "[400] time=10.10, avg_loss=4.0412, train_err=3.4017, 64_h1=0.1110, 64_l2=0.0316\n",
      "[404] time=10.24, avg_loss=4.0426, train_err=3.4029, 64_h1=0.1110, 64_l2=0.0315\n",
      "[408] time=10.02, avg_loss=4.0407, train_err=3.4013, 64_h1=0.1109, 64_l2=0.0319\n",
      "[412] time=10.00, avg_loss=4.0399, train_err=3.4006, 64_h1=0.1107, 64_l2=0.0316\n",
      "[416] time=10.02, avg_loss=4.0389, train_err=3.3998, 64_h1=0.1108, 64_l2=0.0319\n",
      "[420] time=10.39, avg_loss=4.0371, train_err=3.3983, 64_h1=0.1108, 64_l2=0.0314\n",
      "[424] time=10.03, avg_loss=4.0357, train_err=3.3971, 64_h1=0.1107, 64_l2=0.0315\n",
      "[428] time=10.05, avg_loss=4.0341, train_err=3.3957, 64_h1=0.1108, 64_l2=0.0319\n",
      "[432] time=9.98, avg_loss=4.0337, train_err=3.3954, 64_h1=0.1108, 64_l2=0.0318\n",
      "[436] time=10.03, avg_loss=4.0321, train_err=3.3940, 64_h1=0.1106, 64_l2=0.0315\n",
      "[440] time=10.08, avg_loss=4.0309, train_err=3.3930, 64_h1=0.1105, 64_l2=0.0315\n",
      "[444] time=10.17, avg_loss=4.0298, train_err=3.3921, 64_h1=0.1107, 64_l2=0.0321\n",
      "[448] time=9.95, avg_loss=4.0280, train_err=3.3906, 64_h1=0.1105, 64_l2=0.0317\n",
      "[452] time=10.02, avg_loss=4.0262, train_err=3.3891, 64_h1=0.1108, 64_l2=0.0321\n",
      "[456] time=10.11, avg_loss=4.0257, train_err=3.3887, 64_h1=0.1106, 64_l2=0.0319\n",
      "[460] time=9.95, avg_loss=4.0238, train_err=3.3870, 64_h1=0.1103, 64_l2=0.0314\n",
      "[464] time=10.10, avg_loss=4.0231, train_err=3.3865, 64_h1=0.1104, 64_l2=0.0314\n",
      "[468] time=9.95, avg_loss=4.0217, train_err=3.3853, 64_h1=0.1103, 64_l2=0.0313\n",
      "[472] time=10.15, avg_loss=4.0208, train_err=3.3845, 64_h1=0.1104, 64_l2=0.0315\n",
      "[476] time=10.10, avg_loss=4.0192, train_err=3.3832, 64_h1=0.1104, 64_l2=0.0315\n",
      "[480] time=10.03, avg_loss=4.0174, train_err=3.3816, 64_h1=0.1101, 64_l2=0.0313\n",
      "[484] time=10.18, avg_loss=4.0169, train_err=3.3813, 64_h1=0.1104, 64_l2=0.0319\n",
      "[488] time=10.06, avg_loss=4.0160, train_err=3.3804, 64_h1=0.1103, 64_l2=0.0316\n",
      "[492] time=9.97, avg_loss=4.0140, train_err=3.3788, 64_h1=0.1101, 64_l2=0.0315\n",
      "[496] time=10.07, avg_loss=4.0133, train_err=3.3782, 64_h1=0.1102, 64_l2=0.0315\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader=train_loader,\n",
    "              test_loaders={64: test_loader},\n",
    "              optimizer=optimizer, \n",
    "              scheduler=scheduler, \n",
    "              regularizer=False, \n",
    "              training_loss=train_loss, \n",
    "              eval_losses=eval_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), \"./ckpt/TorisLi/\"+model_name+\"_ep500.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_44388/849268122.py\", line 11, in <module>\n",
      "    out = model(x.unsqueeze(0))\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/repo/cfd/myNeuralOperator/neuralop/models/new_fno.py\", line 252, in forward\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/repo/cfd/myNeuralOperator/neuralop/layers/mlp.py\", line 62, in forward\n",
      "    x = fc(x)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Given groups=1, weight of size [256, 3, 1, 1], expected input[1, 1, 64, 64] to have 3 channels, but got 1 channels instead\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = test_loader.dataset\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "for index in range(3):\n",
    "    data = test_samples[index]\n",
    "    # Input x\n",
    "    x = data['x']\n",
    "    # Ground-truth\n",
    "    y = data['y']\n",
    "    # Model prediction\n",
    "    out = model(x.unsqueeze(0))\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 1)\n",
    "    ax.imshow(x[0], cmap='gray')\n",
    "    if index == 0: \n",
    "        ax.set_title('Input x')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 2)\n",
    "    ax.imshow(y.squeeze())\n",
    "    if index == 0: \n",
    "        ax.set_title('Ground-truth y')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 3)\n",
    "    ax.imshow(out.squeeze().detach().numpy())\n",
    "    if index == 0: \n",
    "        ax.set_title('Model prediction')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "fig.suptitle('Inputs, ground-truth output and prediction.', y=0.98)\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
