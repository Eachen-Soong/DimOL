{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/yichen/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from neuralop.models import FNO, F_FNO2D\n",
    "\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import OutputEncoderCallback\n",
    "from neuralop.utils import count_params\n",
    "from neuralop import LpLoss, H1Loss\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "from neuralop.datasets.autoregressive_dataset import load_autoregressive_traintestsplit\n",
    "data_path = \"./data/NavierStokes_V1e-5_N1200_T20.mat\"\n",
    "\n",
    "n_train = 1000\n",
    "n_test = 200\n",
    "batch_size = 32\n",
    "test_batch_size = 64\n",
    "train_subsample_rate = 1\n",
    "test_subsample_rate = 1\n",
    "time_step = 1\n",
    "train_loader, test_loader = load_autoregressive_traintestsplit(\n",
    "    data_path,\n",
    "    n_train, n_test,\n",
    "    batch_size, test_batch_size, \n",
    "    train_subsample_rate, test_subsample_rate,\n",
    "    time_step,\n",
    "    predict_feature='u',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"FFNO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Our FFNO model has 186369 parameters.\n"
     ]
    }
   ],
   "source": [
    "# We create a F-FNO model\n",
    "\n",
    "input_prods = None\n",
    "n_modes=21\n",
    "\n",
    "model = F_FNO2D(in_channels=3, n_modes=(n_modes, n_modes), hidden_channels=32, \n",
    "             projection_channels=64, factorization='tucker', channel_mixing='prod-layer', ffno_channel_mixing='prod', stabilizer='tanh', rank=0.42)\n",
    "\n",
    "# model = FNO(in_channels=3, n_modes=(n_modes, n_modes), hidden_channels=32, \n",
    "#              projection_channels=64, factorization='tucker', channel_mixing='prod-layer', stabilizer='tanh', rank=0.42)\n",
    "\n",
    "# method_name = type(model).__name__.split('.')[-1]\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "n_params = count_params(model)\n",
    "print(f'\\nOur '+model_name+f' model has {n_params} parameters.')\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MODEL ###\n",
      " F_FNO2D(\n",
      "  (fno_blocks): F_FNOBlocks2D(\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (channel_mixer): ModuleList(\n",
      "      (0-3): 4 x ProductLayer(\n",
      "        (linear): MLP(\n",
      "          (fcs): ModuleList(\n",
      "            (0): Conv2d(34, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mixer_skips): ModuleList(\n",
      "      (0-3): 4 x SoftGating()\n",
      "    )\n",
      "    (convs): SpectralConvFFNO2d(\n",
      "      (weight): ModuleList(\n",
      "        (0-7): 8 x ComplexDenseTensor(shape=torch.Size([32, 32, 10]), rank=None)\n",
      "      )\n",
      "      (linear): MLP(\n",
      "        (fcs): ModuleList(\n",
      "          (0): Conv2d(66, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (lifting): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (projection): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.StepLR object at 0x73d6fc081180>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.training.losses.H1Loss object at 0x73d63b34beb0>\n",
      "\n",
      " * Test: {'h1': <neuralop.training.losses.H1Loss object at 0x73d63b34beb0>, 'l2': <neuralop.training.losses.LpLoss object at 0x73d63b34bee0>}\n"
     ]
    }
   ],
   "source": [
    "#Create the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                lr=1e-3, \n",
    "                                weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "# Creating the losses\n",
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "\n",
    "print('\\n### MODEL ###\\n', model)\n",
    "print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "print('\\n### LOSSES ###')\n",
    "print(f'\\n * Train: {train_loss}')\n",
    "print(f'\\n * Test: {eval_losses}')\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "localtime = time.localtime(time.time())\n",
    "time_now = f\"{localtime.tm_mon}-{localtime.tm_mday}-{localtime.tm_hour}-{localtime.tm_min}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 20:14:00.770027: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-26 20:14:00.910943: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-26 20:14:00.911008: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-26 20:14:00.932808: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-26 20:14:00.976756: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-26 20:14:01.663389: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using standard method to load data to device.\n",
      "using standard method to compute loss.\n",
      "self.override_load_to_device=False\n",
      "self.overrides_loss=False\n"
     ]
    }
   ],
   "source": [
    "from neuralop.training import MultipleInputCallback, SimpleTensorBoardLoggerCallback\n",
    "trainer = Trainer(model=model, n_epochs=500,\n",
    "                  device=device,\n",
    "                  callbacks=[MultipleInputCallback(append_positional_encoding=True), SimpleTensorBoardLoggerCallback(log_dir='runs/TorisLi_exp_'+model_name+time_now,)],             \n",
    "                  wandb_log=False,\n",
    "                  log_test_interval=4,\n",
    "                  use_distributed=False,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 19000 samples\n",
      "Testing on [3800] samples         on resolutions [64].\n",
      "Raw outputs of size out.shape=torch.Size([32, 1, 64, 64])\n",
      "[0] time=11.05, avg_loss=0.0149, train_err=0.0004, 64_h1=0.3423, 64_l2=0.1348\n",
      "[4] time=9.86, avg_loss=0.0107, train_err=0.0003, 64_h1=0.2353, 64_l2=0.0833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m              \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtraining_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m              \u001b[49m\u001b[43meval_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_losses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/cfd/myNeuralOperator/neuralop/training/trainer.py:161\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, test_loaders, optimizer, scheduler, regularizer, training_loss, eval_losses)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_batch_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Decide what to do about logging later when we decide on batch naming conventions\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''if epoch == 0 and idx == 0 and self.verbose and is_logger:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m        print(f'Training on raw inputs of size {x.shape=}, {y.shape=}')'''\u001b[39;00m\n",
      "File \u001b[0;32m~/repo/cfd/myNeuralOperator/neuralop/training/callbacks.py:161\u001b[0m, in \u001b[0;36mPipelineCallback.on_batch_start\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_batch_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 161\u001b[0m         \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_batch_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/cfd/myNeuralOperator/neuralop/training/callbacks.py:582\u001b[0m, in \u001b[0;36mMultipleInputCallback.on_batch_start\u001b[0;34m(self, idx, sample)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_batch_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, sample):\n\u001b[0;32m--> 582\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/cfd/myNeuralOperator/neuralop/training/callbacks.py:589\u001b[0m, in \u001b[0;36mMultipleInputCallback.build_features\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    588\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 589\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m     x\u001b[38;5;241m.\u001b[39munsqueeze_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (name, appender) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_appenders:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader=train_loader,\n",
    "              test_loaders={64: test_loader},\n",
    "              optimizer=optimizer, \n",
    "              scheduler=scheduler, \n",
    "              regularizer=False, \n",
    "              training_loss=train_loss, \n",
    "              eval_losses=eval_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model.state_dict(), \"./ckpt/TorisLi/\"+model_name+\"_ep500.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_44388/849268122.py\", line 11, in <module>\n",
      "    out = model(x.unsqueeze(0))\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/repo/cfd/myNeuralOperator/neuralop/models/new_fno.py\", line 252, in forward\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/repo/cfd/myNeuralOperator/neuralop/layers/mlp.py\", line 62, in forward\n",
      "    x = fc(x)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Given groups=1, weight of size [256, 3, 1, 1], expected input[1, 1, 64, 64] to have 3 channels, but got 1 channels instead\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/yichen/anaconda3/envs/test/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_samples = test_loader.dataset\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "for index in range(3):\n",
    "    data = test_samples[index]\n",
    "    # Input x\n",
    "    x = data['x']\n",
    "    # Ground-truth\n",
    "    y = data['y']\n",
    "    # Model prediction\n",
    "    out = model(x.unsqueeze(0))\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 1)\n",
    "    ax.imshow(x[0], cmap='gray')\n",
    "    if index == 0: \n",
    "        ax.set_title('Input x')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 2)\n",
    "    ax.imshow(y.squeeze())\n",
    "    if index == 0: \n",
    "        ax.set_title('Ground-truth y')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "    ax = fig.add_subplot(3, 3, index*3 + 3)\n",
    "    ax.imshow(out.squeeze().detach().numpy())\n",
    "    if index == 0: \n",
    "        ax.set_title('Model prediction')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "\n",
    "fig.suptitle('Inputs, ground-truth output and prediction.', y=0.98)\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
